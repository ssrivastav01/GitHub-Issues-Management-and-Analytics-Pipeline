{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c8a7cc-de53-4725-8ae6-8c128e581b8b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "    \n",
    "### <center> GITHUB ISSUES</center>\n",
    "### <center> ELASTICSEARCH - OPEN AI</center>\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "<br>\n",
    "    <br>\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ffddc3a-6993-4848-bea0-6e392ae30da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.53.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c32c3-fdb5-4391-800f-38864eaaae01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8da7f1d-cc25-452e-9aa1-f019edfd90c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (8.15.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: elastic-transport<9,>=8.13 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from elasticsearch) (8.15.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.2.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\sejal srivastav\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "#Install elastic search\n",
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df79588c-116b-4bc7-86df-e6ce16ce6f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7aee99d-0219-4469-9f8a-d1c32463ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import requests\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d15e9-bc44-4510-b3c5-40632ebc8299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b0610-c0c9-4e04-9068-d332231b904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the headers\n",
    "headers = {\n",
    "    \"Accept\": \"application/vnd.github+json\",\n",
    "    \"access_token\": \"Your access token\",\n",
    "    \"Git_Username\":\"Username\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f3b1c-0863-40a0-b3e0-40e7b26ce0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce5822-6d66-49b7-9523-ba0c3a074da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the owner and the repository\n",
    "owners = ['declare here']\n",
    "repos = ['declare here']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f4a9c-94f6-43d5-8d64-e5521cea24d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decd06a3-5c46-4048-a22b-180bde820141",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "per_page = 100\n",
    "from_date = (dt.date.today() - dt.timedelta(days=35)).isoformat() #The duration for which we need the issues can be changed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116343df-7e18-4c8b-b285-f4bf00534000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c0bc88-58d5-43ff-ad3c-9a8d3cb71e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that returns the base url\n",
    "def fetch_url(owner, repo):\n",
    "    return f\"https://\"+headers[\"Git_Username\"]+\":\"+headers[\"access_token\"]+f\"@api.github.com/repos/{owner}/{repo}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ace28-fedd-461a-92f8-76b870e673af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515dc9c3-429f-4172-a3a9-0d9ba5e96752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the Issues from the GitHub repository\n",
    "issues=[]\n",
    "for owner in owners:\n",
    "    for repo in repos:\n",
    "        # if (owner=='facebook' and repo=='react') or (owner=='openai' and repo=='openai-cookbook') or (owner=='elastic' and repo=='elasticsearch'):\n",
    "        flag = True\n",
    "        url = fetch_url(owner, repo)\n",
    "        while flag:\n",
    "                response = requests.get(f\"{url}/issues\", headers=headers,params={\"since\": from_date, \"page\": page,\"state\":\"all\"})\n",
    "                for obj in response.json():\n",
    "                    if datetime.strptime(from_date, \"%Y-%m-%d\") <= datetime.strptime(obj[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\"):\n",
    "                        issueObject = {\n",
    "                        \"_type\": \"issue\",\n",
    "                        \"_repo\":repo,    \n",
    "                        \"_issueNumber\": str(obj['number']),\n",
    "                        \"_title\": str(obj['title']),\n",
    "                        \"_createdAt\": str(obj['created_at']),\n",
    "                        \"_closedAt\": str(obj['closed_at']) if str(obj['closed_at']) != \"None\" else \"2024-12-31T00:36:30Z\", # Few Issues might still be open, we add \"2024-12-31T00:36:30Z\" as closed date for those Issues.\n",
    "                        \"_state\": str(obj['state']),\n",
    "                        \"_body\": str(obj['body'])[:5000] \n",
    "                            # Here we are considering only the first 5000 characters from the body as \n",
    "                            # there is a limit on the the text tokens that we can embed using the openai model.\n",
    "            # Please refer https://platform.openai.com/docs/guides/embeddings to know more about the embedding models. \n",
    "    \n",
    "            # Please refer to https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb to see how tokens are counted.\n",
    "                    \n",
    "                        }\n",
    "                        issues.append(issueObject)                      \n",
    "                    else:\n",
    "                        flag = False\n",
    "                        break\n",
    "        \n",
    "                if not response.ok or len(response.json()) == 0:\n",
    "                    break\n",
    "        \n",
    "                page+=1          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0321aca6-0c87-43f7-b887-60b85666bd50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7843a0f6-914f-417f-9733-179d3787498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_body': 'None',\n",
      " '_closedAt': '2024-10-31T17:18:51Z',\n",
      " '_createdAt': '2024-10-31T17:02:45Z',\n",
      " '_issueNumber': '676',\n",
      " '_repo': 'SCM587FA24',\n",
      " '_state': 'closed',\n",
      " '_title': 'Fixes #675. SFA24SCM37MAAdding last name.',\n",
      " '_type': 'issue'}\n"
     ]
    }
   ],
   "source": [
    "#Sample Issue\n",
    "pprint(issues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449551ce-f1fd-4c1c-83d3-e4d24fa6ba49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e6c3e7d-032d-414c-88af-db7d82cd4be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665\n"
     ]
    }
   ],
   "source": [
    "#Number of Issues in the given timeframe\n",
    "pprint(len(issues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c232e5-aa18-4187-b838-3a3b1732ff35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68599a46-1c6b-4897-a4e6-190059999f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of Issues to a DataFrame\n",
    "df_Issues = pd.DataFrame(issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ecc4d-cf70-410f-bf16-68bb298a39ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a0a26fa-5fce-4e10-b2b1-5011a43d733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all NaN values with None in columns as elasticsearch does not recognize it\n",
    "df_Issues.fillna(\"None\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76669868-930c-4af6-a8c9-c43b3f2f7af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0ce3ebd-bbd5-4edc-a5ab-ca1ef4c6779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create embeddings from OpenAI API\n",
    "def embed(texts):\n",
    "    # Make a request to OpenAI API to get embeddings\n",
    "    embeddings = client.embeddings.create(\n",
    "        input=texts,\n",
    "        model='text-embedding-ada-002'\n",
    "    )\n",
    "    # Extract embeddings from the API response\n",
    "    return [result.embedding for result in embeddings.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83e0c9-0b7b-48fa-a1a2-6eea57961218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df7bc0-1fd5-485b-a9c2-29283dfe7907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                       | 0/665 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding batch...\n",
      "Waiting for 1 minute before the next batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 665/665 [01:02<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "## Embedding creation using openAI of GitHub Issues.\n",
    "\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Initialize OpenAI client with API key\n",
    "client = OpenAI(api_key=\"Your OPENAPI key\")\n",
    "\n",
    "Issue_embeddings = []\n",
    "\n",
    "# Batch size for processing data\n",
    "batch_size = 500\n",
    "\n",
    "# Initialize data structure for storing text\n",
    "data = [\n",
    "    [], # Titles\n",
    "]\n",
    "count=0;\n",
    "# Embed and insert in batches\n",
    "for i in tqdm(range(0, len(df_Issues))):\n",
    "    title = str(df_Issues.iloc[i]['_title']).replace(\"\\n\", \"\") or ''\n",
    "    body = str(df_Issues.iloc[i]['_body']).replace(\"\\n\", \"\") or ''\n",
    "    \n",
    "    # Merge 'repository name','title' and 'body' of the GitHub Issue\n",
    "    combined_text = f\"Repository:{owner}/{repo} Issue Title:{title} Issue Body:{body}\"  \n",
    "    data[0].append(combined_text)\n",
    "    if len(data[0]) % batch_size == 0:\n",
    "        print(\"Embedding batch...\")\n",
    "\n",
    "        embeddings_batch = embed(data[0]) \n",
    "        Issue_embeddings.extend(embeddings_batch)\n",
    "        data = [[]]\n",
    "        print(\"Waiting for 1 minute before the next batch...\")\n",
    "        \n",
    "        time.sleep(60)    \n",
    "        \n",
    "# Embed the remaining data if any\n",
    "if len(data[0]) != 0:\n",
    "    embeddings_rem = embed(data[0])\n",
    "    print(len(embeddings_rem))\n",
    "    Issue_embeddings.extend(embeddings_rem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340dacbf-ef0a-4f7c-b13f-427c37113eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a630d2f2-346a-4927-8bd6-761b097f09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Generated embeddings to GitHub_Issue_vector column in the dataframe\n",
    "\n",
    "df_Issues[\"GitHub_Issue_vector\"] = Issue_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca323fed-13c1-4636-bebb-dd7c3257e5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a3c634e-a209-4f00-9ed5-59bc16ad45df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_type</th>\n",
       "      <th>_repo</th>\n",
       "      <th>_issueNumber</th>\n",
       "      <th>_title</th>\n",
       "      <th>_createdAt</th>\n",
       "      <th>_closedAt</th>\n",
       "      <th>_state</th>\n",
       "      <th>_body</th>\n",
       "      <th>GitHub_Issue_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>issue</td>\n",
       "      <td>SCM587FA24</td>\n",
       "      <td>16</td>\n",
       "      <td>java</td>\n",
       "      <td>2024-09-27T20:39:45Z</td>\n",
       "      <td>2024-12-31T00:36:30Z</td>\n",
       "      <td>open</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.002798398956656456, -0.004356111865490675,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>issue</td>\n",
       "      <td>SCM587FA24</td>\n",
       "      <td>15</td>\n",
       "      <td>lstm</td>\n",
       "      <td>2024-09-26T17:15:36Z</td>\n",
       "      <td>2024-09-26T17:17:05Z</td>\n",
       "      <td>closed</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.015591975301504135, 0.0011222854955121875,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>issue</td>\n",
       "      <td>SCM587FA24</td>\n",
       "      <td>14</td>\n",
       "      <td>python</td>\n",
       "      <td>2024-09-26T17:14:29Z</td>\n",
       "      <td>2024-12-31T00:36:30Z</td>\n",
       "      <td>open</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.006412663962692022, -0.00413291621953249, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>issue</td>\n",
       "      <td>SCM587FA24</td>\n",
       "      <td>13</td>\n",
       "      <td>flask</td>\n",
       "      <td>2024-09-26T17:12:48Z</td>\n",
       "      <td>2024-12-31T00:36:30Z</td>\n",
       "      <td>open</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.01335589587688446, -0.0061924695037305355,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>issue</td>\n",
       "      <td>SCM587FA24</td>\n",
       "      <td>12</td>\n",
       "      <td>react</td>\n",
       "      <td>2024-09-26T17:10:48Z</td>\n",
       "      <td>2024-09-27T20:38:52Z</td>\n",
       "      <td>closed</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.003074005478993058, 0.0015810404438525438,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _type       _repo _issueNumber  _title            _createdAt  \\\n",
       "660  issue  SCM587FA24           16    java  2024-09-27T20:39:45Z   \n",
       "661  issue  SCM587FA24           15    lstm  2024-09-26T17:15:36Z   \n",
       "662  issue  SCM587FA24           14  python  2024-09-26T17:14:29Z   \n",
       "663  issue  SCM587FA24           13   flask  2024-09-26T17:12:48Z   \n",
       "664  issue  SCM587FA24           12   react  2024-09-26T17:10:48Z   \n",
       "\n",
       "                _closedAt  _state _body  \\\n",
       "660  2024-12-31T00:36:30Z    open  None   \n",
       "661  2024-09-26T17:17:05Z  closed  None   \n",
       "662  2024-12-31T00:36:30Z    open  None   \n",
       "663  2024-12-31T00:36:30Z    open  None   \n",
       "664  2024-09-27T20:38:52Z  closed  None   \n",
       "\n",
       "                                   GitHub_Issue_vector  \n",
       "660  [-0.002798398956656456, -0.004356111865490675,...  \n",
       "661  [-0.015591975301504135, 0.0011222854955121875,...  \n",
       "662  [-0.006412663962692022, -0.00413291621953249, ...  \n",
       "663  [-0.01335589587688446, -0.0061924695037305355,...  \n",
       "664  [-0.003074005478993058, 0.0015810404438525438,...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the new Column is created\n",
    "df_Issues.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682465d1-0413-4e65-8f0d-62a1579bb3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95e897aa-f073-4e35-9c2f-645ae5fdee44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure Elasticsearch connection\n",
    "from elasticsearch import Elasticsearch,helpers\n",
    "es = Elasticsearch(['http://localhost:9200'])\n",
    "es.ping()   #connection testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8622726-a3cf-4a62-a0d9-8d1d57511de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2118a2e8-5c50-49b0-aec5-882a76f606e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'github_issues'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Index Mapping for githubissues\n",
    "\n",
    "index_mapping= {\n",
    "    \"properties\": {\n",
    "      \"GitHub_Issue_vector\": {\n",
    "          \"type\": \"dense_vector\",\n",
    "          \"dims\": 1536,\n",
    "          \"index\": \"true\",\n",
    "          \"similarity\": \"cosine\"\n",
    "      },\n",
    "     \"_type\": {\"type\": \"text\"}, \n",
    "     \"_repo\":{\"type\":\"text\"},   \n",
    "     \"_issueNumber\": {\"type\": \"long\"},    \n",
    "     \"_title\": {\"type\": \"text\"},\n",
    "     \"_createdAt\": {\"type\": \"date\"},\n",
    "     \"_closedAt\": {\"type\": \"date\"},\n",
    "     \"_state\": {\"type\": \"text\"},\n",
    "     \"_body\": {\"type\": \"text\"}\n",
    "   }\n",
    "}\n",
    "index_name = \"spm587fa24_scm587fa24\"\n",
    "if es.indices.exists(index=\"github_issues\"):\n",
    "    es.indices.delete(index=\"github_issues\")\n",
    "\n",
    "es.indices.create(index=\"github_issues\", body={\"mappings\": index_mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dca088-74bc-4d7f-914f-a1d6d382a86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aaa748c-0660-46ae-a0cc-9571ba1c5b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 665 records into Elasticsearch. Failed records: []\n"
     ]
    }
   ],
   "source": [
    "# Bulk indexing for githubissues\n",
    "\n",
    "def dataframe_to_bulk_actions(df_Issues):\n",
    "    for index, row in df_Issues.iterrows():\n",
    "        yield {\n",
    "            \"_index\": 'spm587fa24_scm587fa24',\n",
    "            \"_source\": {\n",
    "                \"_type\": row['_type'],\n",
    "                \"_repo\":row['_repo'],\n",
    "                \"_issueNumber\": row['_issueNumber'],\n",
    "                \"_title\": row['_title'],\n",
    "                \"_createdAt\": row['_createdAt'],\n",
    "                \"_closedAt\": row['_closedAt'],\n",
    "                \"_state\": row['_state'],\n",
    "                \"_body\": row['_body'],\n",
    "                \"GitHub_Issue_vector\": row['GitHub_Issue_vector']\n",
    "            }\n",
    "        }\n",
    "\n",
    "start = 0\n",
    "end = len(df_Issues)\n",
    "batch_size = 500\n",
    "\n",
    "for batch_start in range(start, end, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, end)\n",
    "    batch_dataframe = df_Issues.iloc[batch_start:batch_end]\n",
    "    actions = list(dataframe_to_bulk_actions(df_Issues.iloc[start:end]))\n",
    "    \n",
    "success, failed = helpers.bulk(es, actions)\n",
    "print(f\"Inserted {success} records into Elasticsearch. Failed records: {failed}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac75e1-947c-40c7-bc53-d6159b9becaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
